{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f13xXGAhAbfP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SVM:\n",
        "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        y = y.astype(int)\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                x_i = x_i.astype(float)\n",
        "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
        "                if condition:\n",
        "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
        "                else:\n",
        "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
        "                    self.b -= self.lr * y_[idx]\n",
        "\n",
        "    def predict(self, X):\n",
        "        approx = np.dot(X, self.w) - self.b\n",
        "        return np.where(approx >= 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 1"
      ],
      "metadata": {
        "id": "JfqsdhCxGgps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"/content/project1_dataset1.txt\", sep=\"\\t\")\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "231pM_WrA2Nj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHhKCT8mBfgl",
        "outputId": "e6490e52-6f6b-49f9-de07-e0211bbf7427"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.245e+01, 1.570e+01, 8.257e+01, ..., 1.741e-01, 3.985e-01,\n",
              "        1.244e-01],\n",
              "       [1.126e+01, 1.996e+01, 7.372e+01, ..., 9.314e-02, 2.955e-01,\n",
              "        7.009e-02],\n",
              "       [1.143e+01, 1.539e+01, 7.306e+01, ..., 8.476e-02, 2.676e-01,\n",
              "        6.765e-02],\n",
              "       ...,\n",
              "       [1.450e+01, 1.089e+01, 9.428e+01, ..., 1.221e-01, 2.889e-01,\n",
              "        8.006e-02],\n",
              "       [1.236e+01, 1.854e+01, 7.901e+01, ..., 8.442e-02, 2.983e-01,\n",
              "        7.185e-02],\n",
              "       [1.193e+01, 2.153e+01, 7.653e+01, ..., 7.247e-02, 2.438e-01,\n",
              "        8.541e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6shjKYTBgUZ",
        "outputId": "83ea6c9f-f85d-4987-93a9-18cc79dc06fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 1)"
      ],
      "metadata": {
        "id": "Pw1XCUF0Bhp5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "E3sIkIZHCSSG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9iAmXXBCcxK",
        "outputId": "37615b22-0b0b-425c-97cf-a4d8817267c7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.99066707,  0.92372376,  1.11661305, ...,  1.2841721 ,\n",
              "        -0.96350722,  2.09762058],\n",
              "       [ 2.60015848,  1.69074393,  2.7529165 , ...,  2.3925318 ,\n",
              "         0.48551869,  0.19672436],\n",
              "       [ 1.54225024,  0.89616614,  1.52261315, ...,  1.02700859,\n",
              "        -0.5192685 , -0.43727208],\n",
              "       ...,\n",
              "       [-1.02049004, -0.16020895, -1.02165417, ..., -0.73583978,\n",
              "        -1.1056636 , -0.3061004 ],\n",
              "       [ 0.24107968, -0.12346547,  0.24883908, ..., -0.45356147,\n",
              "        -0.07341438,  0.44595055],\n",
              "       [ 0.49565653,  1.06610475,  0.48915834, ..., -0.03473083,\n",
              "        -0.14287716, -1.15598356]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvip0BLoCeJi",
        "outputId": "d2497009-eff5-44ef-f6e4-6661af9d12fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.53396539, -1.1982123 , -0.53281364, ..., -0.34302627,\n",
              "        -0.35611174,  0.23061038],\n",
              "       [-0.61033845,  0.33353158, -0.57013284, ...,  0.01940885,\n",
              "        -0.6985794 ,  0.86296717],\n",
              "       [-0.81399992,  0.1268495 , -0.81332281, ..., -1.4134882 ,\n",
              "         0.63736756, -1.02754463],\n",
              "       ...,\n",
              "       [-1.32739657,  0.54939954, -1.31938758, ..., -1.15060994,\n",
              "        -0.04110611, -0.05359492],\n",
              "       [-1.01483277,  0.86860853, -1.02206427, ..., -1.24761021,\n",
              "        -1.08304782, -0.88817472],\n",
              "       [-0.59619529,  1.2819727 , -0.58079547, ...,  0.09009122,\n",
              "        -0.48211399, -0.082562  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZNndT5uEPNp",
        "outputId": "3dda795f-0ce5-4bac-e4d7-a2b048a0d5ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUp-Ed88EPEi",
        "outputId": "8bd49619-64bb-4389-f1e9-a611c70cbf37"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVM()\n",
        "\n",
        "classifier.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "HbrK9UmgCgP-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test)"
      ],
      "metadata": {
        "id": "OcaQuiZkDXj7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)\n",
        "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBmL-8MsDcj9",
        "outputId": "bf3fea90-3b98-4105-ea37-bcb40c899de4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdqcLpIRDk1g",
        "outputId": "8071808b-8c97-4162-f8c5-30e4a6a8e1e1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[34  0]\n",
            " [ 0 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(X, y, model, n_splits=10):\n",
        "    kf = []\n",
        "    fold_size = len(X) // n_splits\n",
        "    remainder = len(X) % n_splits\n",
        "    start = 0\n",
        "    for i in range(n_splits):\n",
        "        if i < remainder:\n",
        "            end = start + fold_size + 1\n",
        "        else:\n",
        "            end = start + fold_size\n",
        "        test_indices = list(range(start, end))\n",
        "        train_indices = list(set(range(len(X))) - set(test_indices))\n",
        "        kf.append((train_indices, test_indices))\n",
        "        start = end\n",
        "\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf:\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "    print(\"Accuracy: {:.2f}\".format(np.mean(accuracy_scores)))\n",
        "    print(\"Precision: {:.2f}\".format(np.mean(precision_scores)))\n",
        "    print(\"Recall: {:.2f}\".format(np.mean(recall_scores)))\n",
        "    print(\"F1 Score: {:.2f}\".format(np.mean(f1_scores)))\n",
        "\n",
        "evaluate_model(x, y, classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aZ_NRGsFXbN",
        "outputId": "864dcede-c569-4c74-ac38-46e4fd34af1d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n",
            "Precision: 0.92\n",
            "Recall: 0.68\n",
            "F1 Score: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 2"
      ],
      "metadata": {
        "id": "LssV896sGc05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/project1_dataset2.txt\", sep=\"\\t\")\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "yjMaF0ZiGjD4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vSRAgRZGoNK",
        "outputId": "e6bc3b6f-6917-4441-8870-cfbc5fbca515"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[123, 0.05, 4.61, ..., 23.23, 2.78, 16],\n",
              "       [128, 0.5, 3.7, ..., 21.25, 22.73, 28],\n",
              "       [114, 9.6, 2.51, ..., 25.67, 40.63, 46],\n",
              "       ...,\n",
              "       [138, 4.5, 2.85, ..., 24.78, 24.89, 56],\n",
              "       [170, 7.6, 5.5, ..., 37.41, 6.17, 54],\n",
              "       [128, 0.0, 10.58, ..., 28.41, 14.66, 48]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FCE9uB6GoxN",
        "outputId": "a9fde98d-48f0-469c-e6a0-36fc13bfdeff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47rnTT-QGpSv",
        "outputId": "a809fc23-b267-4ace-ef1e-6c5d07b310d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Absent', 'Present', 'Absent', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Present', 'Present', 'Present',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Absent', 'Present',\n",
              "       'Present', 'Present', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Present', 'Absent', 'Absent', 'Present', 'Present',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Absent', 'Present', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Present', 'Present',\n",
              "       'Absent', 'Absent', 'Absent', 'Present', 'Present', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Absent', 'Present',\n",
              "       'Absent', 'Present', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Present', 'Present', 'Absent', 'Absent', 'Present',\n",
              "       'Present', 'Absent', 'Absent', 'Present', 'Absent', 'Absent',\n",
              "       'Present', 'Present', 'Present', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Present', 'Present', 'Absent', 'Present', 'Present',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Absent', 'Present',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Absent', 'Present',\n",
              "       'Present', 'Present', 'Present', 'Present', 'Absent', 'Present',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Present',\n",
              "       'Absent', 'Present', 'Absent', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Present', 'Absent', 'Present',\n",
              "       'Present', 'Absent', 'Absent', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Present', 'Present', 'Absent', 'Present',\n",
              "       'Absent', 'Absent', 'Absent', 'Present', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Present', 'Absent', 'Present', 'Absent', 'Present',\n",
              "       'Absent', 'Present', 'Absent', 'Present', 'Present', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Present', 'Absent', 'Present',\n",
              "       'Absent', 'Absent', 'Present', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Present', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Present', 'Present',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Absent', 'Present',\n",
              "       'Absent', 'Present', 'Absent', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Present', 'Present', 'Absent',\n",
              "       'Absent', 'Absent', 'Present', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Absent', 'Present',\n",
              "       'Absent', 'Absent', 'Present', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Present', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Present', 'Absent', 'Present',\n",
              "       'Present', 'Absent', 'Present', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Present', 'Absent', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Present', 'Absent', 'Present',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Present', 'Present',\n",
              "       'Absent', 'Present', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Present', 'Present',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Absent', 'Present',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Present', 'Absent', 'Present', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Absent', 'Absent', 'Present', 'Absent',\n",
              "       'Absent', 'Absent', 'Absent', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Present', 'Present', 'Absent', 'Absent', 'Absent',\n",
              "       'Present', 'Present', 'Present', 'Present', 'Present', 'Absent',\n",
              "       'Present', 'Absent', 'Present', 'Absent', 'Absent', 'Absent',\n",
              "       'Absent', 'Present', 'Present', 'Present', 'Absent', 'Present',\n",
              "       'Present', 'Present', 'Absent', 'Present', 'Present'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "_MjqZrg_GxHr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_KqxrOeG7_l",
        "outputId": "c1b280e2-0178-4d5c-c710-11a1c7efb60f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.61, 3.7, 2.51, 6.38, 4.69, 10.53, 4.01, 6.53, 3.17, 9.78, 2.58,\n",
              "       2.63, 4.82, 7.18, 6.57, 5.09, 2.66, 7.63, 5.73, 5.63, 5.11, 4.75,\n",
              "       1.96, 4.9, 4.89, 4.67, 5.62, 1.87, 6.99, 3.47, 3.12, 8.53, 6.68,\n",
              "       1.71, 3.36, 5.97, 2.19, 5.41, 4.91, 3.17, 5.46, 4.94, 4.89, 4.99,\n",
              "       4.16, 6.08, 7.1, 3.89, 3.17, 7.32, 2.68, 5.56, 4.42, 4.22, 5.9,\n",
              "       2.36, 8.41, 3.65, 4.55, 1.88, 4.79, 2.73, 6.23, 3.96, 3.59, 3.63,\n",
              "       3.66, 5.59, 4.68, 2.44, 7.22, 3.69, 3.84, 4.18, 3.2, 14.16, 3.98,\n",
              "       2.44, 3.66, 6.26, 3.38, 5.9, 7.85, 1.82, 1.77, 8.46, 2.85, 3.57,\n",
              "       6.63, 3.54, 8.29, 3.16, 4.9, 2.81, 6.33, 6.09, 3.22, 10.49, 3.68,\n",
              "       1.96, 2.83, 4.14, 8.49, 11.17, 9.19, 1.86, 5.29, 5.04, 5.08, 6.41,\n",
              "       7.04, 3.3, 2.05, 2.96, 2.51, 2.8, 3.24, 5.05, 2.28, 3.58, 5.59,\n",
              "       3.52, 6.22, 6.13, 8.12, 3.02, 5.21, 5.35, 2.82, 5.05, 4.43, 5.32,\n",
              "       3.57, 8.28, 6.65, 4.37, 1.07, 4.8, 1.94, 3.14, 3.95, 4.66, 3.26,\n",
              "       6.41, 2.43, 1.88, 12.42, 6.06, 8.12, 6.58, 4.31, 5.13, 5.01, 2.95,\n",
              "       4.33, 6.89, 5.13, 4.16, 4.92, 6.95, 3.63, 8.22, 3.57, 5.8, 5.96,\n",
              "       2.7, 4.04, 5.04, 5.1, 2.66, 1.82, 2.4, 6.34, 2.71, 3.58, 3.91,\n",
              "       4.39, 5.55, 5.28, 4.37, 3.69, 6.14, 6.4, 3.18, 4.37, 7.14, 6.76,\n",
              "       2.78, 2.28, 3.08, 6.38, 4.17, 5.63, 5.8, 1.59, 4.04, 4.97, 7.02,\n",
              "       3.3, 4.98, 3.28, 2.72, 3.55, 1.43, 4.13, 3.24, 6.06, 4.64, 5.03,\n",
              "       3.82, 5.98, 4.41, 4.79, 4.89, 2.99, 4.19, 4.15, 5.9, 0.98, 4.16,\n",
              "       3.12, 1.87, 4.02, 3.54, 3.95, 4.81, 5.53, 3.38, 4.41, 3.27, 4.3,\n",
              "       4.82, 3.37, 4.65, 3.79, 3.72, 5.26, 10.19, 3.2, 9.01, 5.98, 4.77,\n",
              "       7.21, 4.55, 4.63, 5.52, 1.8, 7.13, 5.45, 4.03, 5.73, 2.55, 4.32,\n",
              "       3.14, 5.03, 4.23, 3.56, 5.88, 8.07, 5.47, 3.41, 3.31, 7.99, 3.5,\n",
              "       5.38, 3.16, 2.63, 5.91, 4.71, 3.81, 4.44, 3.73, 15.33, 4.31, 3.3,\n",
              "       3.78, 3.58, 5.56, 5.0, 5.24, 1.72, 5.51, 3.9, 4.99, 3.67, 4.96,\n",
              "       5.49, 3.08, 2.01, 2.74, 2.77, 1.74, 4.24, 8.8, 5.91, 2.77, 8.22,\n",
              "       5.08, 3.98, 4.24, 5.81, 2.83, 3.12, 5.09, 5.67, 3.14, 5.76, 4.6,\n",
              "       11.41, 4.87, 8.01, 6.17, 4.64, 2.99, 5.29, 4.37, 4.86, 2.94, 4.69,\n",
              "       3.37, 3.98, 4.19, 3.23, 5.75, 6.03, 5.63, 4.37, 2.33, 7.26, 3.84,\n",
              "       3.95, 1.55, 9.05, 3.95, 3.31, 3.58, 1.88, 6.25, 5.19, 2.76, 4.75,\n",
              "       2.42, 6.49, 2.91, 4.11, 3.95, 4.0, 3.51, 3.2, 2.43, 3.97, 4.26,\n",
              "       2.42, 7.75, 3.83, 4.55, 3.74, 11.89, 3.79, 3.51, 5.24, 7.27, 3.69,\n",
              "       8.55, 3.09, 11.61, 2.44, 6.39, 5.17, 5.28, 4.51, 7.95, 7.41, 2.4,\n",
              "       3.79, 2.58, 7.46, 7.4, 2.39, 7.56, 3.04, 2.28, 3.67, 6.94, 2.7,\n",
              "       6.03, 6.32, 7.24, 3.48, 3.7, 4.17, 3.92, 4.0, 2.98, 3.76, 3.18,\n",
              "       5.97, 4.59, 2.46, 5.86, 3.96, 7.18, 3.4, 9.12, 2.84, 4.44, 7.41,\n",
              "       3.1, 4.19, 2.46, 9.65, 7.39, 2.47, 3.53, 6.62, 5.64, 3.99, 2.79,\n",
              "       7.22, 2.4, 3.57, 4.17, 6.16, 4.34, 4.9, 3.05, 4.12, 3.05, 4.21,\n",
              "       8.03, 4.49, 4.16, 4.75, 2.29, 7.84, 3.29, 4.93, 8.13, 7.67, 5.15,\n",
              "       4.34, 5.58, 2.42, 3.57, 7.03, 3.86, 3.91, 4.99, 2.97, 3.3, 3.88,\n",
              "       2.69, 6.73, 11.32, 2.4, 6.06, 4.59, 2.53, 2.85, 5.5, 10.58],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 1)"
      ],
      "metadata": {
        "id": "OJkwkVADHMq6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "Ryn4UPrwG9D0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVM()\n",
        "\n",
        "classifier.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "owZKpZsCHXZG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test)"
      ],
      "metadata": {
        "id": "lNPcOTnoHWZt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjJXRpl1HOwu",
        "outputId": "161a63c7-b9a6-4d0d-ede9-ff1496571232"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1\n",
            " 0 0 0 1 0 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0DJ98UtHfYr",
        "outputId": "d533dc8e-2512-4e59-b42f-39b129c5e010"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[24  0]\n",
            " [12 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(x, y, classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mobeHeUBHeqH",
        "outputId": "b0d25f25-ee85-41aa-86fa-9a7dbb74095d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.59\n",
            "Precision: 0.24\n",
            "Recall: 0.40\n",
            "F1 Score: 0.26\n"
          ]
        }
      ]
    }
  ]
}